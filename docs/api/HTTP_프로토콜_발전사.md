# HTTP/1.1부터 HTTP/3까지

HTTP는 단순한 전송 프로토콜이 아니라 **API의 계약(contract)** 이다.
HTTP/1.1 이후의 변화는 “HTTP의 의미를 유지하면서, 전송 방식과 운영 모델을 어떻게 개선해왔는가”의 역사라고 볼 수 있다.

이 글에서는 **HTTP/1.1 → HTTP/2 → HTTP/3**의 발전 과정을
RFC 문서를 기준으로 살펴보고,
각 버전에서 **기존에 어떤 문제가 있었고, 그것이 어떻게 해결되었는지**를
구체적인 사례 중심으로 정리한다.

---

## 1. HTTP/1.1 — 현대 HTTP의 출발점

HTTP/1.1은 단순한 버전 업이 아니라
**“인터넷 규모에서 운영 가능한 HTTP”를 처음으로 정의한 표준**이다.

### 기존에는 이랬다 (HTTP/1.0의 한계)

- 요청마다 TCP 연결 생성/종료
- 프록시, 캐시, 게이트웨이를 명확히 고려하지 않음

### HTTP/1.1에서 이렇게 바뀌었다

#### 1) 지속 연결 (Persistent Connection)

- 기존: TCP 연결 → 요청 → 응답 → 연결 종료

HTTP/1.1: TCP 연결 → 요청 A → 응답 A
→ 요청 B → 응답 B
→ 요청 C → 응답 C
(연결 유지)

- HTTP/1.0은 TCP 연결 → 요청 → 응답 → 연결 종료
- 하나의 TCP 연결에서 여러 요청/응답 처리
- 네트워크 왕복(RTT) 비용 대폭 감소
- 서버의 연결 생성/종료 부담 완화-

#### 2) 프록시·캐시·게이트웨이를 전제로 한 설계

HTTP/1.1은 다음과 같은 현실적인 구조를 **표준으로 인정**했다.

Client → Proxy → CDN → Gateway → Origin Server

- 헤더 파싱 규칙 강화
- 메시지 전달 및 라우팅 규칙 명확화
- 캐시 동작(ETag, If-Modified-Since 등) 정식 정의

#### 3) HTTP 의미론(Semantics)의 명문화

- 메서드의 의미와 멱등성
- 상태 코드의 의도
- 캐시 가능 여부

👉 이 시점부터 **API 설계는 HTTP 의미를 존중해야 하는 문제**가 되었다.

> HTTP/1.1은 “웹 페이지를 가져오는 프로토콜”에서
> “플랫폼과 API를 운영하는 프로토콜”로 HTTP를 끌어올렸다.

---

## 2. HTTP/2 — 전송 효율의 근본적 개선

HTTP/1.1은 운영 측면에서는 성공했지만,
성능 측면에서는 구조적 한계를 가지고 있었다.

### 기존에는 이랬다 (HTTP/1.1)

- 한 연결에서 여러 요청 가능
- 하지만 **응답은 순서대로 처리**
  - 요청 A → 응답 A 완료
  - 요청 B → 응답 B 완료
  - 요청 C → 응답 C 완료
- 앞선 요청이 느리면 뒤 요청도 대기
- 브라우저는 병렬성을 위해 여러 TCP 연결을 생성

### HTTP/2에서 이렇게 바뀌었다

HTTP/2는 **HTTP 의미는 그대로 유지**한 채
전송 방식을 완전히 재설계했다.

#### 1) 멀티플렉싱

[단일 TCP 연결]
Stream 1: GET /index.html
Stream 3: GET /style.css
Stream 5: GET /app.js

- 하나의 연결에서 여러 요청/응답 동시 처리
- 느린 요청이 빠른 요청을 막지 않음

#### 2) 바이너리 프레이밍

기존:

- 텍스트 기반 메시지 파싱

HTTP/2:

- 바이너리 프레임 단위 처리
- 파싱 효율 향상
- 구현 오류 감소

#### 3) 헤더 압축 (HPACK)

기존:

- 매 요청마다 인증, 쿠키 헤더 반복 전송

HTTP/2:

- 헤더 테이블 기반 압축
- 모바일·고지연 환경에서 효과적

### 여전히 남은 문제

- HTTP/2는 **TCP 기반**
- TCP는 패킷 순서를 보장

👉 한 패킷 손실 시 모든 스트림이 대기
(일반적으로 TCP HOL(Head-of-Line Blocking) 문제로 설명됨)

> HTTP/2는 애플리케이션 레벨 병목은 해결했지만
> 전송 계층의 병목은 남겨두었다.

**[관련 RFC]**

- RFC 9113 — HTTP/2
- RFC 7541 — HPACK Header Compression

---

## 3. HTTP/3 — 전송 계층 자체를 바꾸다

HTTP/3는 HTTP/2의 문제를 “튜닝”으로 해결하지 않았다.
대신 **TCP를 포기하고 QUIC 위로 이동**했다.

### 기존에는 이랬다 (HTTP/2 + TCP)

- 스트림은 분리되어 있지만
- TCP는 연결 단위로 재전송

패킷 손실 → 모든 스트림 지연

### HTTP/3에서 이렇게 바뀌었다 (QUIC 기반)

[QUIC 연결]
Stream A 손실 → Stream A만 재전송
Stream B, C → 영향 없음

#### 1) 스트림 단위 손실 격리

- 요청 간 간섭 최소화
- 모바일, 무선 네트워크에서 안정성 향상

#### 2) 빠른 연결 수립

- TLS가 전송 계층에 통합
- 핸드셰이크 RTT 감소

#### 3) 네트워크 이동성

- IP 변경에도 연결 유지 가능
- Wi-Fi ↔ LTE 전환 시 효과적

#### 4) 헤더 압축 방식 변경 (QPACK)

- HTTP/2: HPACK
- HTTP/3: QPACK
- 손실 환경에서도 헤더 블로킹 최소화

> HTTP/3는 “더 빠른 HTTP”라기보다
> “실패에 강한 HTTP”에 가깝다.

**[관련 RFC]**

- RFC 9114 — HTTP/3
- RFC 9000 — QUIC Transport Protocol
- RFC 9204 — QPACK Header Compression

---

## 4. API 설계·아키텍처 관점에서 달라진 고민

### 사례 1: 재시도는 항상 발생한다

- 네트워크 손실
- 클라이언트 타임아웃
- SDK/프록시의 자동 재시도

👉 POST 요청도 멱등성을 고려해야 함
(Idempotency-Key, 중복 요청 방지)

### 사례 2: 연결 수 제한은 더 이상 안전하지 않다

- HTTP/2/3에서는 한 연결에서 다수 요청 가능
- 기존 “커넥션 제한” 전략 무력화

👉 요청 단위, 사용자 단위 레이트 리밋 필요

### 사례 3: 관측 포인트의 변화

기존:

- 커넥션 중심 모니터링

현재:

- Request ID / Trace ID 중심 추적
- 요청 단위 지연·실패·재시도 분석

---

## 5. 정리

HTTP의 진화는 다음 질문에 대한 연속적인 답이다.

- **HTTP/1.1:** “인터넷 규모로 운영하려면?”
- **HTTP/2:** “왜 이렇게 느린가?”
- **HTTP/3:** “왜 이렇게 자주 끊기는가?”

그리고 API 개발자는 이제 이렇게 질문해야 한다.

> “이 API는 실패와 재시도를 전제로 설계되었는가?”

프로토콜은 계속 진화하지만,
**신뢰성은 여전히 아키텍처의 책임**이다.
